{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d54a6768-c95e-431f-aecd-fc4365b50729",
   "metadata": {},
   "source": [
    "Every module/layer in PyTorch subclasses `nn.Module`. Here we build a model to classify the FashionMNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e23b126b-74ad-4d7c-a3c1-0358d20c9f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader \n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1d1acdd-09df-44fe-8c32-17a6d3c1ebd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d9f8d28-c306-4587-bb73-fafc2d3629ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    # initialize the layers in __init__ \n",
    "    def __init__(self):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "    \n",
    "    # every nn.Module subclass implements the operations\n",
    "    # on input data in the forward method\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "321031b2-169b-4e85-bc5b-a5cfbe2eb4c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNet(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# create an instance of NeuralNet and move it to the device \n",
    "# and prints its structure\n",
    "model = NeuralNet().to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5a932fab-70ae-4770-8494-9b3d67680c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits:\n",
      " tensor([[-0.0529, -0.0290, -0.0683, -0.0517, -0.0141, -0.0064, -0.0648,  0.0112,\n",
      "         -0.0105, -0.0253]], grad_fn=<AddmmBackward0>)\n",
      "pred_prob:\n",
      " tensor([[0.0978, 0.1002, 0.0963, 0.0979, 0.1017, 0.1025, 0.0967, 0.1043, 0.1021,\n",
      "         0.1006]], grad_fn=<SoftmaxBackward0>)\n",
      "predicted class:\n",
      " tensor([7])\n"
     ]
    }
   ],
   "source": [
    "# X is one random image (28*28 pixels matrice)\n",
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "print(f\"logits:\\n {logits}\")\n",
    "pred_prob = nn.Softmax(dim=1)(logits)\n",
    "print(f\"pred_prob:\\n {pred_prob}\")\n",
    "y_pred = pred_prob.argmax(1)\n",
    "print(f\"predicted class:\\n {y_pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "484df713-5b01-4a37-aca6-3c1a7bb99421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1698, 0.6401, 0.9141,  ..., 0.5754, 0.0915, 0.3493],\n",
       "         [0.2870, 0.9838, 0.6591,  ..., 0.7330, 0.4444, 0.0334],\n",
       "         [0.3381, 0.1555, 0.8735,  ..., 0.9459, 0.5256, 0.5829],\n",
       "         ...,\n",
       "         [0.1317, 0.4292, 0.0351,  ..., 0.3460, 0.9050, 0.5769],\n",
       "         [0.9101, 0.5752, 0.7337,  ..., 0.1006, 0.1500, 0.6448],\n",
       "         [0.5326, 0.7913, 0.3438,  ..., 0.8404, 0.7613, 0.5359]],\n",
       "\n",
       "        [[0.7991, 0.4153, 0.7676,  ..., 0.5111, 0.0519, 0.6828],\n",
       "         [0.1036, 0.1688, 0.8555,  ..., 0.5817, 0.2393, 0.4748],\n",
       "         [0.2353, 0.4067, 0.3573,  ..., 0.3784, 0.8680, 0.7492],\n",
       "         ...,\n",
       "         [0.1080, 0.8656, 0.9572,  ..., 0.3794, 0.8536, 0.7911],\n",
       "         [0.2099, 0.7409, 0.4736,  ..., 0.2020, 0.6695, 0.4065],\n",
       "         [0.6189, 0.4603, 0.9020,  ..., 0.8841, 0.6310, 0.5967]],\n",
       "\n",
       "        [[0.6085, 0.8624, 0.3412,  ..., 0.8852, 0.8280, 0.1239],\n",
       "         [0.6048, 0.4830, 0.4760,  ..., 0.0383, 0.9964, 0.0899],\n",
       "         [0.1420, 0.7001, 0.5563,  ..., 0.2758, 0.4613, 0.0511],\n",
       "         ...,\n",
       "         [0.6196, 0.3893, 0.7481,  ..., 0.5091, 0.8131, 0.9774],\n",
       "         [0.8661, 0.4599, 0.0768,  ..., 0.7601, 0.6948, 0.7691],\n",
       "         [0.9394, 0.9677, 0.8275,  ..., 0.0328, 0.1407, 0.5785]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a sample minibatch of 3 images of size 28x28\n",
    "input_image = torch.rand(3, 28, 28)\n",
    "print(input_image.size())\n",
    "input_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6530a78c-a4e3-4544-8519-93e7c25adf18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 784])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.1698, 0.6401, 0.9141,  ..., 0.8404, 0.7613, 0.5359],\n",
       "        [0.7991, 0.4153, 0.7676,  ..., 0.8841, 0.6310, 0.5967],\n",
       "        [0.6085, 0.8624, 0.3412,  ..., 0.0328, 0.1407, 0.5785]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flatten = nn.Flatten()\n",
    "flat_image = flatten(input_image)\n",
    "print(flat_image.size())\n",
    "flat_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "25365d2e-a54d-40d9-865e-204be77f47ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 20])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0618,  0.4944,  0.0778,  0.5778,  0.5266, -0.0043, -0.1944, -0.0483,\n",
       "         -0.3917, -0.1207, -0.0785,  0.4999, -0.0391,  0.2558,  0.2724,  0.2816,\n",
       "          0.0992, -0.3392,  0.3312, -0.1209],\n",
       "        [ 0.1175,  0.8568,  0.2291,  0.5376,  0.6717, -0.2213, -0.1995, -0.1520,\n",
       "         -0.4277, -0.0190, -0.1352,  0.6526, -0.1882,  0.2640,  0.2507,  0.0662,\n",
       "         -0.0216, -0.2648,  0.3321,  0.2048],\n",
       "        [-0.1206,  0.5289,  0.2122,  0.5381,  0.6254, -0.0936, -0.3246, -0.4594,\n",
       "         -0.4243,  0.0403, -0.2283,  0.9413, -0.0146,  0.1529,  0.2474,  0.4443,\n",
       "          0.0868, -0.1364,  0.0500, -0.1638]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the linear layer is a module that applies a linear transformation \n",
    "# on the input using its stored weights and biases\n",
    "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
    "hidden1 = layer1(flat_image)\n",
    "print(hidden1.size())\n",
    "hidden1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a9aa70-ded5-4a6f-9e93-97ff93133f7d",
   "metadata": {},
   "source": [
    "Non-linear activations are what create the complex mappings between the model’s inputs and outputs. They are applied after linear transformations to introduce nonlinearity, helping neural networks learn a wide variety of phenomena."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ed67f14-1c6f-4a30-a7b9-8b8a5e4f34e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before ReLU:\n",
      " tensor([[-0.0618,  0.4944,  0.0778,  0.5778,  0.5266, -0.0043, -0.1944, -0.0483,\n",
      "         -0.3917, -0.1207, -0.0785,  0.4999, -0.0391,  0.2558,  0.2724,  0.2816,\n",
      "          0.0992, -0.3392,  0.3312, -0.1209],\n",
      "        [ 0.1175,  0.8568,  0.2291,  0.5376,  0.6717, -0.2213, -0.1995, -0.1520,\n",
      "         -0.4277, -0.0190, -0.1352,  0.6526, -0.1882,  0.2640,  0.2507,  0.0662,\n",
      "         -0.0216, -0.2648,  0.3321,  0.2048],\n",
      "        [-0.1206,  0.5289,  0.2122,  0.5381,  0.6254, -0.0936, -0.3246, -0.4594,\n",
      "         -0.4243,  0.0403, -0.2283,  0.9413, -0.0146,  0.1529,  0.2474,  0.4443,\n",
      "          0.0868, -0.1364,  0.0500, -0.1638]], grad_fn=<AddmmBackward0>)\n",
      "after ReLU:\n",
      " tensor([[0.0000, 0.4944, 0.0778, 0.5778, 0.5266, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.4999, 0.0000, 0.2558, 0.2724, 0.2816, 0.0992, 0.0000,\n",
      "         0.3312, 0.0000],\n",
      "        [0.1175, 0.8568, 0.2291, 0.5376, 0.6717, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.6526, 0.0000, 0.2640, 0.2507, 0.0662, 0.0000, 0.0000,\n",
      "         0.3321, 0.2048],\n",
      "        [0.0000, 0.5289, 0.2122, 0.5381, 0.6254, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0403, 0.0000, 0.9413, 0.0000, 0.1529, 0.2474, 0.4443, 0.0868, 0.0000,\n",
      "         0.0500, 0.0000]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"before ReLU:\\n {hidden1}\")\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print(f\"after ReLU:\\n {hidden1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b4d856d-831d-4ddc-be82-2207a51929be",
   "metadata": {},
   "source": [
    "`nn.Sequential` is an ordered container of modules. The data is passed through all the modules in the same order as defined. You can use sequential containers to put together a quick network like `seq_modules`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4401ae7b-204b-489c-ae81-a71abd1d288c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1099, -0.0872, -0.2717,  0.0881,  0.0162, -0.5116,  0.1605, -0.2554,\n",
       "          0.0309,  0.5082],\n",
       "        [-0.1598,  0.0551, -0.1110,  0.1366,  0.0703, -0.6088,  0.2912, -0.1996,\n",
       "          0.1731,  0.4252],\n",
       "        [-0.1646, -0.0639, -0.1984,  0.1282,  0.2406, -0.6302,  0.3010, -0.2357,\n",
       "          0.0694,  0.4131]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_modules = nn.Sequential(\n",
    "    flatten,\n",
    "    layer1,\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20, 10)\n",
    ")\n",
    "input_image = torch.rand(3, 28, 28)\n",
    "logits = seq_modules(input_image)\n",
    "logits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb146d8-2ddb-4080-a143-c8d6ddf6804e",
   "metadata": {},
   "source": [
    "The last linear layer of the neural network returns logits - raw values in [-infty, infty] - which are passed to the `nn.Softmax` module. The logits are scaled to values [0, 1] representing the model’s predicted probabilities for each class. `dim` parameter indicates the dimension along which the values must sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "02b3a502-77c8-4b0c-9e3d-4f83c6c6113c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0903, 0.0923, 0.0768, 0.1100, 0.1024, 0.0604, 0.1183, 0.0780, 0.1039,\n",
       "         0.1675],\n",
       "        [0.0816, 0.1012, 0.0857, 0.1098, 0.1027, 0.0521, 0.1281, 0.0784, 0.1139,\n",
       "         0.1465],\n",
       "        [0.0826, 0.0913, 0.0798, 0.1107, 0.1238, 0.0518, 0.1315, 0.0769, 0.1043,\n",
       "         0.1471]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "pred_prob = softmax(logits)\n",
    "pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6e48576c-5403-4a07-ad1b-67f0a5349801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model structure:\n",
      " NeuralNet(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "\n",
      "\n",
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values:\n",
      " tensor([[ 0.0055,  0.0169,  0.0306,  ..., -0.0017, -0.0210,  0.0297],\n",
      "        [ 0.0155,  0.0314, -0.0341,  ..., -0.0245,  0.0039, -0.0274]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values:\n",
      " tensor([0.0087, 0.0126], grad_fn=<SliceBackward0>)\n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values:\n",
      " tensor([[-0.0191,  0.0140, -0.0292,  ..., -0.0093,  0.0428,  0.0365],\n",
      "        [-0.0132, -0.0311, -0.0419,  ...,  0.0119,  0.0276, -0.0148]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values:\n",
      " tensor([-0.0244, -0.0047], grad_fn=<SliceBackward0>)\n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values:\n",
      " tensor([[ 0.0041,  0.0294, -0.0016,  ..., -0.0086,  0.0319, -0.0411],\n",
      "        [-0.0095,  0.0103,  0.0099,  ...,  0.0212,  0.0014,  0.0353]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values:\n",
      " tensor([-0.0276, -0.0083], grad_fn=<SliceBackward0>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# accessing model parameters\n",
    "print(f\"Model structure:\\n {model}\\n\\n\")\n",
    "\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"Layer: {name} | Size: {param.size()} | Values:\\n {param[:2]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82621836-499f-4892-bd5d-737a3487d3e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
